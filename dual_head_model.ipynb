{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Text classification with Dual-Head Model\n",
        "\n",
        "The purpose of this code is to perform text classification using a dual-head neural network model. The objective is to classify text based on both the gender of author (male or female) and the date of the first edition (before or after 1900) simultaneously. The code can be divided into the following sections:\n",
        "\n",
        "**Setting Up Environment:**<br>\n",
        "\n",
        " - Importing necessary libraries (numpy, warnings, random, and torch).\n",
        "Setting up random seeds for reproducibility.\n",
        "\n",
        "**Loading and Preprocessing Data:**<br>\n",
        "\n",
        " - Loading TF-IDF features from a NumPy file (tf-idf.npy).\n",
        " - Reading labels for sex and year from text files (sex.txt and year.txt).\n",
        " - Splitting the data into training and testing sets using train_test_split.\n",
        "\n",
        "**Defining the Neural Network Model:**<br>\n",
        "\n",
        " - Creating a neural network class (MyNet) with specific layers (fc1, fc_sex, fc_year).\n",
        " - Initializing an instance of the neural network.\n",
        "\n",
        "**Training the Neural Network:**<br>\n",
        "\n",
        " - Defining loss function (CrossEntropyLoss) and optimizer (Adam).\n",
        " - Iterating through epochs and batches, performing forward and backward passes, updating weights.\n",
        "\n",
        "**Testing the Neural Network:**<br>\n",
        "\n",
        " - Evaluating the trained model on the test set.\n",
        " - Calculating accuracy and F1 scores for both sex and year predictions.\n",
        "\n"
      ],
      "metadata": {
        "id": "HILjw_aVkNNI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0. Setting Up Environment"
      ],
      "metadata": {
        "id": "qZXp879fzO1_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8PJuL5hPE0e"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import warnings\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Set random seed\n",
        "setup_seed(20)"
      ],
      "metadata": {
        "id": "eq4uu7PzRS1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Loading and Preprocessing Data"
      ],
      "metadata": {
        "id": "TsUZENSozULG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF-IDF matrix\n",
        "tf_fit = np.load('tf-idf.npy', allow_pickle=True)\n",
        "print(tf_fit.shape)"
      ],
      "metadata": {
        "id": "XdMnhCbjRPeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sex labels\n",
        "with open('sex.txt', 'r') as f:\n",
        "    sex_list = [line.rstrip('\\n') for line in f]\n",
        "sex_list = [int(x)-1 for x in sex_list]\n",
        "print(len(sex_list))\n",
        "\n",
        "# Load year labels\n",
        "with open('year.txt', 'r') as f:\n",
        "    year_list = [line.rstrip('\\n') for line in f]\n",
        "year_list = [0 if int(x) < 2000 else 1 for x in year_list]\n",
        "print(len(year_list))"
      ],
      "metadata": {
        "id": "2hFmVHO2Pd2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine labels\n",
        "labels =  list(zip(sex_list, year_list))\n",
        "print(labels[0])"
      ],
      "metadata": {
        "id": "oTOIr3OwPfnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(tf_fit, labels, test_size=0.3, random_state=2024)"
      ],
      "metadata": {
        "id": "Y-Mwtt0ePhp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract individual labels\n",
        "y_train_sex = np.array([x[0] for x in y_train])\n",
        "y_train_year = np.array([x[1] for x in y_train])\n",
        "y_test_sex = np.array([x[0] for x in y_test])\n",
        "y_test_year = np.array([x[1] for x in y_test])"
      ],
      "metadata": {
        "id": "3Tn6OI2IRmP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "R9SdBXnbRppE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_trn_torch = torch.from_numpy(x_train)\n",
        "Y_trn_torch_sex = torch.from_numpy(y_train_sex)\n",
        "Y_trn_torch_year = torch.from_numpy(y_train_year)\n",
        "X_tst_torch = torch.from_numpy(x_test)\n",
        "Y_tst_torch_sex = torch.from_numpy(y_test_sex)\n",
        "Y_tst_torch_year = torch.from_numpy(y_test_year)\n",
        "\n",
        "# Create PyTorch datasets\n",
        "torch_trn_dataset = Data.TensorDataset(X_trn_torch, Y_trn_torch_sex, Y_trn_torch_year)\n",
        "torch_tst_dataset = Data.TensorDataset(X_tst_torch, Y_tst_torch_sex, Y_tst_torch_year)\n",
        "\n",
        "# Batch size\n",
        "bsize = 16\n",
        "\n",
        "# Create PyTorch data loaders\n",
        "trainloader = Data.DataLoader(\n",
        "    dataset=torch_trn_dataset,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")\n",
        "\n",
        "testloader = Data.DataLoader(\n",
        "    dataset=torch_tst_dataset,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")"
      ],
      "metadata": {
        "id": "Rt401Xz8P19I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Defining the Neural Network Model"
      ],
      "metadata": {
        "id": "LTDU75VrzbwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet,self).__init__()\n",
        "        self.fc1 = nn.Linear(10000,100)\n",
        "        self.fc_sex = nn.Linear(100,2)\n",
        "        self.fc_year = nn.Linear(100,2)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x_sex = self.fc_sex(x)\n",
        "        x_year = self.fc_year(x)\n",
        "        return x_sex, x_year"
      ],
      "metadata": {
        "id": "nK24XmQKPyj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Training and Testing the Neural Network"
      ],
      "metadata": {
        "id": "Ldl2IqATzi97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the neural network\n",
        "net = MyNet().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
        "\n",
        "# Train the network\n",
        "for epoch in range(20):  # Iterate over 20 epochs\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, slabels, ylabels = data\n",
        "        inputs = inputs.to(torch.float32)\n",
        "        slabels = slabels.to(torch.int64)\n",
        "        ylabels = ylabels.to(torch.int64)\n",
        "        inputs, slabels, ylabels = inputs.to(device), slabels.to(device), ylabels.to(device)\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = net(inputs)  # Forward pass\n",
        "        loss = criterion(outputs[0], slabels) + criterion(outputs[1], ylabels)  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    # Test the network\n",
        "    scorrect = 0\n",
        "    stotal = 0\n",
        "    sall_predicted = []\n",
        "    sall_labels = []\n",
        "    ycorrect = 0\n",
        "    ytotal = 0\n",
        "    yall_predicted = []\n",
        "    yall_labels = []\n",
        "    with torch.no_grad():  # During testing, we don't need to compute gradients\n",
        "        for inputs, slabels, ylabels in testloader:\n",
        "            # Ensure data is on the correct device\n",
        "            inputs = inputs.to(torch.float32)\n",
        "            slabels = slabels.to(torch.int64)\n",
        "            ylabels = ylabels.to(torch.int64)\n",
        "\n",
        "            inputs, slabels, ylabels = inputs.to(device), slabels.to(device), ylabels.to(device)\n",
        "\n",
        "            outputs = net(inputs)  # Forward pass\n",
        "            _, spredicted = torch.max(outputs[0].data, 1)  # Get predicted results\n",
        "            _, ypredicted = torch.max(outputs[1].data, 1)  # Get predicted results\n",
        "            stotal += slabels.size(0)\n",
        "            scorrect += (spredicted == slabels).sum().item()\n",
        "\n",
        "            # Save predicted results and true labels for calculating F1 score\n",
        "            sall_predicted.extend(spredicted.cpu().numpy())\n",
        "            sall_labels.extend(slabels.cpu().numpy())\n",
        "\n",
        "            ytotal += ylabels.size(0)\n",
        "            ycorrect += (ypredicted == ylabels).sum().item()\n",
        "\n",
        "            # Save predicted results and true labels for calculating F1 score\n",
        "            yall_predicted.extend(ypredicted.cpu().numpy())\n",
        "            yall_labels.extend(ylabels.cpu().numpy())\n",
        "\n",
        "    saccuracy = 100 * scorrect / stotal\n",
        "    sf1 = f1_score(sall_labels, sall_predicted, average='macro')\n",
        "    print(f'Epoch {epoch+1}, sAccuracy: {saccuracy}%, sF1 Score: {sf1}')\n",
        "\n",
        "    yaccuracy = 100 * ycorrect / ytotal\n",
        "    yf1 = f1_score(yall_labels, yall_predicted, average='macro')\n",
        "    print(f'Epoch {epoch+1}, yAccuracy: {yaccuracy}%, yF1 Score: {yf1}')"
      ],
      "metadata": {
        "id": "ubXZ4ry9P5OJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}