{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Text classification with Single-Head Model\n",
        "\n",
        "The purpose of this code is to perform text classification using a single-head neural network model. The objective is to classify text based on the gender of the author (male or female). The code can be divided into the following sections:\n",
        "\n",
        "**Setting Up Environment:**<br>\n",
        "\n",
        " - Importing necessary libraries: NumPy for numerical operations, warnings for  - suppressing warnings, random for setting random seeds, and PyTorch for building and training neural networks.\n",
        " - Setting up random seeds for reproducibility to ensure consistent results across runs.\n",
        "\n",
        "**Loading and Preprocessing Data:**<br>\n",
        "\n",
        " - Loading the TF-IDF features from a NumPy file ('tf-idf.npy') into the variable tf_fit.\n",
        " - Reading sex labels from a text file ('sex.txt'), reducing each label by 1, and storing them in the sex_list.\n",
        " - Combining labels into labels, which represents the sex labels.\n",
        " - Splitting the dataset into training and testing sets using the train_test_split function.\n",
        "\n",
        "**Defining the Neural Network Model:**<br>\n",
        "\n",
        " - Creating a neural network class named MyNet that inherits from nn.Module.\n",
        " - The neural network has one hidden layer (fc1) with ReLU activation and an output layer (fc_sex) for binary sex classification.\n",
        " - Initializing an instance of the neural network, named net.\n",
        "\n",
        "**Training the Neural Network:**<br>\n",
        "\n",
        " - Defining the loss function as cross-entropy loss (nn.CrossEntropyLoss) and the optimizer as Adam (optim.Adam).\n",
        " - Iterating through 20 epochs and batches, performing forward and backward passes, and updating the weights.\n",
        " - The training process aims to minimize the cross-entropy loss.\n",
        "\n",
        "**Testing the Neural Network:**<br>\n",
        "\n",
        " - Evaluating the trained model on the test set.\n",
        " - Calculating accuracy and F1 score for sex predictions.\n",
        " - Printing the accuracy and F1 score for each epoch during training."
      ],
      "metadata": {
        "id": "VgBk2XbbqqEI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 0. Setting Up Environment"
      ],
      "metadata": {
        "id": "hPKdu14UyZVi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fm1rf-jSqhTo"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import warnings\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Set random seed\n",
        "setup_seed(20)"
      ],
      "metadata": {
        "id": "ZikTWpbdr8au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Loading and Preprocessing Data"
      ],
      "metadata": {
        "id": "ysEHnxwHyBdL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TF-IDF matrix\n",
        "tf_fit = np.load('tf-idf.npy', allow_pickle=True)\n",
        "print(tf_fit.shape)"
      ],
      "metadata": {
        "id": "UBdQ4XU5r8pz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sex labels\n",
        "with open('sex.txt', 'r') as f:\n",
        "    sex_list = [line.rstrip('\\n') for line in f]\n",
        "sex_list = [int(x)-1 for x in sex_list]\n",
        "print(len(sex_list))"
      ],
      "metadata": {
        "id": "vuHO-jH2r83d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine labels\n",
        "labels = sex_list\n",
        "print(labels[0])"
      ],
      "metadata": {
        "id": "Hq3QuvCwr9Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset\n",
        "x_train, x_test, y_train, y_test = train_test_split(tf_fit, labels, test_size=0.3, random_state=2024)"
      ],
      "metadata": {
        "id": "DOBWX03hsOaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose device (CPU or GPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "DD2CMFLIsg27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert data to PyTorch tensors\n",
        "X_trn_torch = torch.from_numpy(x_train)\n",
        "Y_trn_torch_sex = torch.from_numpy(np.array(y_train))\n",
        "X_tst_torch = torch.from_numpy(x_test)\n",
        "Y_tst_torch_sex = torch.from_numpy(np.array(y_test))\n",
        "\n",
        "# Create PyTorch datasets\n",
        "torch_trn_dataset = Data.TensorDataset(X_trn_torch, Y_trn_torch_sex)\n",
        "torch_tst_dataset = Data.TensorDataset(X_tst_torch, Y_tst_torch_sex)\n",
        "\n",
        "# Batch size\n",
        "bsize = 16\n",
        "\n",
        "# Create PyTorch data loaders\n",
        "trainloader = Data.DataLoader(\n",
        "    dataset=torch_trn_dataset,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")\n",
        "\n",
        "testloader = Data.DataLoader(\n",
        "    dataset=torch_tst_dataset,\n",
        "    batch_size=bsize,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        ")"
      ],
      "metadata": {
        "id": "CEG-jgcNsg7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Defining the Neural Network Model"
      ],
      "metadata": {
        "id": "qTsAx5nDyGW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(10000, 100)\n",
        "        self.fc_sex = nn.Linear(100, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x_sex = self.fc_sex(x)\n",
        "        return x_sex"
      ],
      "metadata": {
        "id": "EUPnUL92sg_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the neural network\n",
        "net = MyNet().to(device)\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "QzdPct0cyM2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. Training and Testing the Neural Network"
      ],
      "metadata": {
        "id": "Yx033nUYyOc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the network\n",
        "for epoch in range(20):  # Iterate over 20 epochs\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, slabels = data\n",
        "        inputs = inputs.to(torch.float32)\n",
        "        slabels = slabels.to(torch.int64)\n",
        "        inputs, slabels = inputs.to(device), slabels.to(device)\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = net(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, slabels)  # Calculate loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "    # Test the network\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():  # During testing, we don't need to compute gradients\n",
        "        for inputs, slabels in testloader:\n",
        "            # Ensure data is on the correct device\n",
        "            inputs = inputs.to(torch.float32)\n",
        "            slabels = slabels.to(torch.int64)\n",
        "\n",
        "            inputs, slabels = inputs.to(device), slabels.to(device)\n",
        "\n",
        "            outputs = net(inputs)  # Forward pass\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get predicted results\n",
        "            total += slabels.size(0)\n",
        "            correct += (predicted == slabels).sum().item()\n",
        "\n",
        "            # Save predicted results and true labels for calculating F1 score\n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(slabels.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    f1 = f1_score(all_labels, all_predicted, average='macro')\n",
        "    print(f'Epoch {epoch+1}, Accuracy: {accuracy}%, F1 Score: {f1}')"
      ],
      "metadata": {
        "id": "yk1EKye2zLl8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}